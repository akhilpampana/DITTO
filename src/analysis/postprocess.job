#!/bin/bash
#
#SBATCH --job-name=post_process_gnomad_indel
#SBATCH --output=logs/post_process_gnomad_indel.out
#
# Number of tasks needed for this job. Generally, used with MPI jobs
#SBATCH --ntasks=1
#SBATCH --partition=amd-hdr100
#
# Number of CPUs allocated to each task.
#SBATCH --cpus-per-task=1
#SBATCH --time=06-06:00:00
#
# Mimimum memory required per allocated  CPU  in  MegaBytes.
#SBATCH --mem=10G
#
# Send mail to the email address when the job fails
#SBATCH --mail-type=FAIL

#Set your environment here
# module reset
# ml Anaconda3
conda activate csvkit

#Modify paths and run the pipeline here
set -euo pipefail

# Merge all the files after DITTO pipeline
find /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/snvs -name "*.csv.gz" -print0 | xargs -0 zcat | csvcut -c chrom,pos,ref_base,alt_base,transcript,gene,consequence,DITTO | csvformat -T | awk -v OFS='\t' '{print > "/data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/all_snv/DITTO_"$1"_merged.tsv"}'

echo "merging files successful!"

sort -t$'\t' -k1,1 -k2,2n -T $USER_SCRATCH /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/all_snv/DITTO_chrY_merged.tsv >/data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/all_snv/DITTO_chrY_merged.tsv_sorted.tsv

echo "sorting successful!"
