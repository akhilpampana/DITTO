#!/bin/bash
#
#SBATCH --job-name=CAGI_try
#SBATCH --output=logs/CAGI_try.out
#
# Number of tasks needed for this job. Generally, used with MPI jobs
#SBATCH --ntasks=1
#SBATCH --partition=short
##SBATCH --partition=pascalnodes
##SBATCH --gres=gpu:1
#
# Number of CPUs allocated to each task.
#SBATCH --cpus-per-task=10
#
# Mimimum memory required per allocated  CPU  in  MegaBytes.
#SBATCH --mem=70G
#
# Send mail to the email address when the job fails
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=tmamidi@uab.edu

#Set your environment here
module reset
#module load cuda11.8/toolkit
#module load cuDNN/8.2.1.32-CUDA-11.3.1
module load Anaconda3


#Run your training scripts here
#source activate training

#python training/NN.py --train_x /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/train_data_3_star/train_class_data_80.csv.gz --test_x /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/train_data_3_star/test_class_data_20.csv.gz -c /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/configs/col_config.yaml -o /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/train_data_3_star_PB


#python training/benchmark_consequence.py --test_x /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/train_data_3_star/test_data_20.csv.gz --test_y /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/train_data_3_star/test_data-y_20.csv.gz -c /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/configs/col_config.yaml -d /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/train_data_3_star -o /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/train_data_3_star/benchmarking

#Run your testing scripts here
#module load tabix
#module load BCFtools
#Check if there is chr in chromosome position column
#grep -v ^# hgmd_pro_2020.4_hg38.vcf | cut -f1 -d$'\t' | sort -u
#sed -E -i 's/(^[^#]+)/chr\1/' /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/external/variants_onTranscript_VEP_37.vcf

#Index and normalize the VCF
#bgzip -c  /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/external/variants_onTranscript_VEP_37.vcf > /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/external/variants_onTranscript_VEP_37.vcf.gz

#tabix -fp vcf /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/external/variants_onTranscript_VEP_37.vcf.gz

#bcftools norm -f /data/project/worthey_lab/temp_datasets_central/mana/gatk_bundle/b37/data/human_g1k_v37.fasta /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/external/variants_onTranscript_VEP_37.vcf.gz -Oz -o /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/interim/variants_onTranscript_VEP_37.vcf.gz

#source activate opencravat

#zcat /data/project/worthey_lab/projects/experimental_pipelines/mana/small_tasks/cagi6/rgp/data/interim/single_sample_vcf/train/homref_removed/CAGI6_RGP_TRAIN_22_PROBAND.vcf.gz  | grep -v "^#" | cut -d$'\t' -f1,2,4,5 | grep -v "*" | gzip > /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/interim/cagi6/CAGI6_RGP_TRAIN_22_PROBAND.txt.gz

#oc run /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/external/UDN249098.txt -l hg38 -t csv --package mypackage -d /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/interim/

source activate training

#python src/parse_predict.py -i /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/interim/cagi6/CAGI6_RGP_TRAIN_22_PROBAND.txt.gz.variant.csv -e parse_predict -o /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/cagi6/CAGI6_RGP_TRAIN_22_PROBAND.csv.gz -c /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/configs/opencravat_test_config.json

python src/annotation_parsing/parse.py -i /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/interim/cagi6/CAGI6_RGP_TRAIN_22_PROBAND.txt.gz.variant.csv.gz -e parse -o /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/interim/cagi6/CAGI6_RGP_TRAIN_22_PROBAND.csv.gz -c /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/configs/opencravat_test_config.json

#source activate training
#
python src/predict/predict.py -i /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/interim/cagi6/CAGI6_RGP_TRAIN_22_PROBAND.csv.gz -o /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/cagi6 -c /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/configs/col_config.yaml -d /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/train_data_3_star/
