#!/bin/bash
#
#SBATCH --job-name=snv
#SBATCH --output=logs/samplesheet1.out
#
# Number of tasks needed for this job. Generally, used with MPI jobs
#SBATCH --ntasks=1
#SBATCH --partition=amd-hdr100
#SBATCH --time=06-06:00:00
#SBATCH --nodelist=c0215,c0216
#
# Number of CPUs allocated to each task.
#SBATCH --cpus-per-task=1
#
# Mimimum memory required per allocated  CPU  in  MegaBytes.
#SBATCH --mem=10G
#
# Send mail to the email address when the job fails
#SBATCH --mail-type=FAIL

#Set your environment here
module reset
ml Java/13.0.2
ml Anaconda3
#conda activate nextflow

#Modify paths and run the pipeline here
#rm -rf /local/modules
if [ ! -d "/local/modules" ]; then
  cp -r "/data/project/worthey_lab/projects/experimental_pipelines/tarun/opencravat/modules" "/local/modules"
  echo "Database copied to /local/modules"
else
  echo "The directory /local/modules already exists. Database not copied."
fi

/data/project/worthey_lab/tools/nextflow/nextflow-22.10.7/nextflow run pipeline_test.nf \
  --outdir /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/test \
  -work-dir ${USER_SCRATCH}/snv \
  --build hg38 -c cheaha.config -with-report
#--sample_sheet /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/file_parts/file_list_partaa

#https://training.nextflow.io/basic_training/cache_and_resume/#how-to-organize-in-silico-experiments
