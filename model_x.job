#!/bin/bash
#
#SBATCH --job-name=snv
#SBATCH --output=logs/snv_TM_x.out
#
# Number of tasks needed for this job. Generally, used with MPI jobs
#SBATCH --ntasks=1
#SBATCH --partition=long
#
# Number of CPUs allocated to each task.
#SBATCH --cpus-per-task=1
#
# Mimimum memory required per allocated  CPU  in  MegaBytes.
#SBATCH --mem=10G
#
# Send mail to the email address when the job fails
#SBATCH --mail-type=FAIL

#Set your environment here
module reset
ml Java/13.0.2
ml Anaconda3
#conda activate nextflow


#Modify paths and run the pipeline here
/data/project/worthey_lab/tools/nextflow/nextflow-22.10.7/nextflow run pipeline.nf \
  --outdir /data/project/worthey_lab/projects/experimental_pipelines/tarun/DITTO/data/processed/snv \
  -work-dir ${USER_SCRATCH}/snv \
  --vcf_path /data/project/worthey_lab/temp_datasets_central/tarun/cadd/split/snvs/x\* \
  --build hg38 -c cheaha.config  -with-report -resume

